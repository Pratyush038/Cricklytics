{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f93097a1-b221-42eb-8a42-4d3d793ce601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f76f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://stats.espncricinfo.com/ci/engine/stats/index.html?class=6;filter=advanced;orderby=runs;size=200;template=results;trophy=117;type=batting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c8cfad9-19e3-4290-99ba-dfb17827b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Referer\": \"https://www.espncricinfo.com/\",\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "html_content = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94015e7b-8863-4858-9c03-e43bb18e99ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_batting_data(html_content):\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    tables = soup.select(\"table.engineTable\")\n",
    "\n",
    "\n",
    "    my_table = tables[2]\n",
    "\n",
    "    # Get all rows from the tbody (third child of table)\n",
    "    rows = my_table.find_all(\"tr\")[1:]  # Skipping header row\n",
    "    batting_data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) < 10:\n",
    "            continue  # Skip if the row doesn't have enough columns\n",
    "        \n",
    "        temp_data = {\n",
    "            \"player\": cols[0].text.strip(),\n",
    "            \"span\": cols[1].text.strip(),\n",
    "            \"mat\": cols[2].text.strip(),\n",
    "            \"runs\": cols[5].text.strip(),\n",
    "            \"avg\": cols[7].text.strip(),\n",
    "            \"sr\": cols[9].text.strip(),\n",
    "            \"fours\": cols[13].text.strip(),\n",
    "            \"sixes\":cols[14].text.strip(),\n",
    "        }\n",
    "        batting_data.append(temp_data)\n",
    "    return batting_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df388d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bowling_data(html_content):\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    tables = soup.select(\"table.engineTable\")\n",
    "    if len(tables) < 3:\n",
    "        return []\n",
    "    my_table = tables[2]\n",
    "\n",
    "    rows = my_table.find_all(\"tr\")[1:]\n",
    "    bowling_data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) < 11:\n",
    "            continue \n",
    "        temp_data = {\n",
    "            \"player\": cols[0].text.strip().split(\"\\n\")[0],\n",
    "            \"span\": cols[1].text.strip(),\n",
    "            \"mat\": cols[2].text.strip(),\n",
    "            \"wickets\": cols[7].text.strip(),\n",
    "            \"econ\": cols[10].text.strip(),\n",
    "        }\n",
    "        bowling_data.append(temp_data)\n",
    "    return bowling_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90e5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "batting_data = []\n",
    "bowling_data = []\n",
    "data = [batting_data, bowling_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce19ec90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in range(1,5):\\n    link = r\"https://stats.espncricinfo.com/ci/engine/stats/index.html?class=6;filter=advanced;orderby=runs;page={};size=200;template=results;trophy=117;type=batting\"\\n    r = requests.get(link.format(i), headers=headers)\\n    html_content = r.text\\n    parsed_data = extract_batting_data(html_content=html_content)\\n    batting_data.extend(parsed_data)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is only for ipl\n",
    "# #https://stats.espncricinfo.com/ci/engine/stats/index.html?class=6;filter=advanced;orderby=runs;page=1;size=200;template=results;trophy=117;type=batting\n",
    "'''for i in range(1,5):\n",
    "    link = r\"https://stats.espncricinfo.com/ci/engine/stats/index.html?class=6;filter=advanced;orderby=runs;page={};size=200;template=results;trophy=117;type=batting\"\n",
    "    r = requests.get(link.format(i), headers=headers)\n",
    "    html_content = r.text\n",
    "    parsed_data = extract_batting_data(html_content=html_content)\n",
    "    batting_data.extend(parsed_data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data from all major t20 leagues\n",
    "#https://stats.espncricinfo.com/ci/engine/stats/index.html?class=6;filter=advanced;orderby=runs;page=1;size=200;template=results;trophy=117;type=batting\n",
    "for i in range(1,11):\n",
    "    link = r\"https://stats.espncricinfo.com/ci/engine/stats/index.html?class=6;filter=advanced;orderby=runs;page={};size=200;template=results;trophy=117;trophy=120;trophy=142;trophy=158;trophy=159;trophy=167;trophy=205;trophy=52;trophy=730;trophy=748;trophy=765;trophy=865;trophy=89;trophy=942;trophy=985;trophy=987;type=batting\"\n",
    "    r = requests.get(link.format(i), headers=headers)\n",
    "    html_content = r.text\n",
    "    parsed_data = extract_batting_data(html_content=html_content)\n",
    "    batting_data.extend(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87186d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bowling data only for ipl\n",
    "#https://stats.espncricinfo.com/ci/engine/stats/index.html?class=6;filter=advanced;orderby=runs;page=1;size=200;template=results;trophy=117;type=batting\n",
    "\n",
    "'''for i in range(1,5):\n",
    "    link = r\"https://stats.espncricinfo.com/ci/engine/stats/index.html?class=6;filter=advanced;orderby=wickets;page={};size=200;template=results;trophy=117;type=bowling\"\n",
    "    r = requests.get(link.format(i), headers=headers)\n",
    "    html_content = r.text\n",
    "    parsed_data = extract_bowling_data(html_content=html_content)\n",
    "    bowling_data.extend(parsed_data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b03e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bowling data for all t20 leagues\n",
    "# https://stats.espncricinfo.com/ci/engine/stats/index.html?class=6;filter=advanced;orderby=wickets;page=2;size=200;template=results;trophy=117;trophy=120;trophy=142;trophy=158;trophy=159;trophy=167;trophy=205;trophy=52;trophy=730;trophy=748;trophy=765;trophy=865;trophy=89;trophy=942;trophy=985;trophy=987;type=bowling\n",
    "for i in range(1,11):\n",
    "    link = r\"https://stats.espncricinfo.com/ci/engine/stats/index.html?class=6;filter=advanced;orderby=wickets;page={};size=200;template=results;trophy=117;trophy=120;trophy=142;trophy=158;trophy=159;trophy=167;trophy=205;trophy=52;trophy=730;trophy=748;trophy=765;trophy=865;trophy=89;trophy=942;trophy=985;trophy=987;type=bowling\"\n",
    "    r = requests.get(link.format(i), headers=headers)\n",
    "    html_content = r.text\n",
    "    parsed_data = extract_bowling_data(html_content=html_content)\n",
    "    bowling_data.extend(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(data[0][:2], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe729b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data[0])\n",
    "#print(json.dumps(data[0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80189312",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_df = pd.DataFrame.from_dict(data[0])\n",
    "batting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowling_df = pd.DataFrame.from_dict(data[1])\n",
    "bowling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258107ca-91ab-4e9b-a694-411d784aa83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [batting_df, bowling_df]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b729f-c6aa-46cc-9a41-dd4f8768ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Handle missing values\n",
    "for d in df:\n",
    "    \n",
    "    d = d.dropna()\n",
    "# Remove missing rows (or use df.fillna(value) to replace them)\n",
    "#df[0]\n",
    "#df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[0].columns)\n",
    "print(df[1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847cadd-c2df-43f7-bc0f-6dc7855edaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process batting data\n",
    "d = df[0] # Access Batting DataFrame\n",
    "\n",
    "\n",
    "d[\"mat\"] = pd.to_numeric(d[\"mat\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "d[\"runs\"] = d[\"runs\"].astype(str).str.replace(\",\", \"\", regex=True).replace([\"-\", \"DNB\", \"NA\", \"\"], \"0\").astype(int)\n",
    "d[\"avg\"] = pd.to_numeric(d[\"avg\"], errors=\"coerce\").fillna(0).astype(float)\n",
    "d[\"sr\"] = pd.to_numeric(d[\"sr\"], errors=\"coerce\").fillna(0).astype(float)\n",
    "d[\"fours\"] = pd.to_numeric(d[\"fours\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "d[\"sixes\"] = pd.to_numeric(d[\"sixes\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "\n",
    "d[[\"start_year\", \"end_year\"]] = d[\"span\"].str.split(\"-\", expand=True).astype(int)\n",
    "d[\"career_length\"] = d[\"end_year\"] - d[\"start_year\"] + 1\n",
    "\n",
    "\n",
    "print(d.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251f4af-686b-4a77-9ba5-1c6592dcb2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Bowling Data\n",
    "d = df[1]  # Access bowling DataFrame\n",
    "\n",
    "d[\"mat\"] = pd.to_numeric(d[\"mat\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "d[\"wickets\"] = (\n",
    "    d[\"wickets\"]\n",
    "    .astype(str)  \n",
    "    .str.replace(\",\", \"\", regex=True)  \n",
    "    .replace([\"-\", \"DNB\", \"NA\", \"\"], \"0\")  \n",
    "    .astype(int)  \n",
    ")\n",
    "d[\"econ\"] = pd.to_numeric(d[\"econ\"], errors=\"coerce\").fillna(0).astype(float)\n",
    "\n",
    "\n",
    "d[\"start_year\"] = d[\"span\"].apply(lambda x: int(x.split(\"-\")[0]) if isinstance(x, str) else 0)\n",
    "d[\"end_year\"] = d[\"span\"].apply(lambda x: int(x.split(\"-\")[1]) if isinstance(x, str) else 0)\n",
    "d[\"career_length\"] = d[\"end_year\"] - d[\"start_year\"] + 1\n",
    "\n",
    "print(d.head())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f33f3-414c-4e9d-9608-bd706f96732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select batting DataFrame\n",
    "d = df[0].copy()  # Work on a copy to avoid modifying the original\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Columns to scale (EXCLUDING start_year, end_year, span)\n",
    "cols_to_scale = [\"mat\", \"runs\", \"avg\", \"sr\", \"career_length\", \"fours\", \"sixes\"]\n",
    "\n",
    "# Apply MinMaxScaler only on relevant columns\n",
    "d[cols_to_scale] = scaler.fit_transform(d[cols_to_scale])\n",
    "\n",
    "# Print the transformed DataFrame\n",
    "print(d.head())'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd16ed-0c5e-4fd7-8336-31435d08d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select batting DataFrame\n",
    "d = df[1].copy()  # Work on a copy to avoid modifying the original\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Columns to scale (EXCLUDING start_year, end_year, span)\n",
    "cols_to_scale = [\"mat\", \"wickets\", \"econ\", \"career_length\"]\n",
    "\n",
    "# Apply MinMaxScaler only on relevant columns\n",
    "d[cols_to_scale] = scaler.fit_transform(d[cols_to_scale])\n",
    "\n",
    "# Print the transformed DataFrame\n",
    "print(d.head())'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acbc2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define columns for visualization\n",
    "features = [\"mat\", \"runs\", \"avg\", \"sr\", \"career_length\", \"fours\", \"sixes\"]\n",
    "d = df[0].copy()\n",
    "# Plot histograms\n",
    "d[features].hist(figsize=(12, 6), bins=20, edgecolor=\"black\")\n",
    "plt.suptitle(\"Distribution of Batting Features\", fontsize=14)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb5adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].to_csv(\"batting_data.csv\", index=\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db8bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1].to_csv(\"bowling_data.csv\", index=\"False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Initial Attempt to train model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"batting_data.csv\")  # Replace with actual dataset path\n",
    "\n",
    "# Feature Selection & Scaling\n",
    "features = [\"mat\", \"runs\", \"avg\", \"sr\", \"career_length\"]\n",
    "X = df[features]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Filtering Low-Experience Players\n",
    "low_experience_threshold = 10  # Players with less than 10 matches\n",
    "low_experience_players = df[df[\"mat\"] < low_experience_threshold].copy()\n",
    "high_experience_players = df[df[\"mat\"] >= low_experience_threshold].copy()\n",
    "\n",
    "# Clustering using K-Means on high-experience players\n",
    "num_clusters = 4  # Anchor, Balanced, Power Hitter, Finisher\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "high_experience_players.loc[:, \"cluster\"] = kmeans.fit_predict(X_pca[high_experience_players.index])\n",
    "\n",
    "# Assign Roles Based on Clusters\n",
    "role_mapping = {\n",
    "    0: \"Anchor\",\n",
    "    1: \"Balanced Player\",\n",
    "    2: \"Power Hitter\",\n",
    "    3: \"Finisher\"\n",
    "}\n",
    "high_experience_players.loc[:, \"role\"] = high_experience_players[\"cluster\"].map(role_mapping)\n",
    "low_experience_players.loc[:, \"role\"] = \"Low Experience\"\n",
    "\n",
    "# Combine Data Back\n",
    "df_final = pd.concat([high_experience_players, low_experience_players])\n",
    "\n",
    "# Supervised Learning - Neural Network\n",
    "X_final = df_final[features]\n",
    "y_final = df_final[\"role\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution:\", Counter(y_train))\n",
    "\n",
    "# Hyperparameter tuning for Neural Network\n",
    "nn_params = {\n",
    "    'hidden_layer_sizes': [(256, 128, 64), (512, 256, 128)],  # Larger networks for better representation\n",
    "    'activation': ['relu'],  # ReLU for deep networks\n",
    "    'alpha': [0.0005, 0.001],  # Regularization to reduce overfitting\n",
    "    'learning_rate_init': [0.005],  # Balanced learning rate\n",
    "    'max_iter': [1500, 2000]  # More iterations for better convergence\n",
    "}\n",
    "nn_model = GridSearchCV(MLPClassifier(random_state=42), nn_params, cv=3)\n",
    "nn_model.fit(X_train, y_train)\n",
    "y_pred_nn = nn_model.best_estimator_.predict(X_test)\n",
    "\n",
    "# Model Evaluation\n",
    "print(\"Neural Network Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef768e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"batting_data.csv\")  # Updated file name\n",
    "\n",
    "# Feature Selection & Scaling\n",
    "features = [\"mat\", \"runs\", \"avg\", \"sr\", \"career_length\"]\n",
    "X = df[features]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Define Inexperienced Batters (less than 100 runs OR less than 10 matches)\n",
    "inexperienced_players = df[(df[\"mat\"] < 10) | (df[\"runs\"] < 100)].copy()\n",
    "experienced_players = df[(df[\"mat\"] >= 10) & (df[\"runs\"] >= 100)].copy()\n",
    "\n",
    "# Clustering using K-Means on experienced players\n",
    "num_clusters = 4  # Anchor, Balanced, Power Hitter, Finisher\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "experienced_players.loc[:, \"cluster\"] = kmeans.fit_predict(X_pca[experienced_players.index])\n",
    "\n",
    "# Assign Roles Based on Clusters\n",
    "role_mapping = {\n",
    "    0: \"Anchor\",\n",
    "    1: \"Balanced Player\",\n",
    "    2: \"Power Hitter\",\n",
    "    3: \"Finisher\"\n",
    "}\n",
    "experienced_players.loc[:, \"role\"] = experienced_players[\"cluster\"].map(role_mapping)\n",
    "inexperienced_players.loc[:, \"role\"] = \"Inexperienced Batter\"\n",
    "\n",
    "# Combine Data Back\n",
    "df_final = pd.concat([experienced_players, inexperienced_players])\n",
    "\n",
    "# Supervised Learning - Neural Network\n",
    "X_final = df_final[features]\n",
    "y_final = df_final[\"role\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution:\", Counter(y_train))\n",
    "\n",
    "# Hyperparameter tuning for Neural Network\n",
    "nn_params = {\n",
    "    'hidden_layer_sizes': [(256, 128, 64), (512, 256, 128)],  # Larger networks for better representation\n",
    "    'activation': ['relu'],  # ReLU for deep networks\n",
    "    'alpha': [0.0005, 0.001],  # Regularization to reduce overfitting\n",
    "    'learning_rate_init': [0.005],  # Balanced learning rate\n",
    "    'max_iter': [1500, 2000]  # More iterations for better convergence\n",
    "}\n",
    "nn_model = GridSearchCV(MLPClassifier(random_state=42), nn_params, cv=3)\n",
    "nn_model.fit(X_train, y_train)\n",
    "y_pred_nn = nn_model.best_estimator_.predict(X_test)\n",
    "\n",
    "# Model Evaluation\n",
    "print(\"Neural Network Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e275fefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Training  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, log_loss\n",
    "import joblib  # For saving the unified model\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"batting_data.csv\")\n",
    "\n",
    "# Feature Engineering - Adding Boundary Percentage\n",
    "df[\"boundary_pct\"] = ((4 * df[\"fours\"] + 6 * df[\"sixes\"]) / df[\"runs\"]) * 100\n",
    "\n",
    "\n",
    "features = [\"mat\", \"runs\", \"avg\", \"sr\", \"career_length\", \"fours\", \"sixes\", \"boundary_pct\"]\n",
    "X = df[features].fillna(df[features].mean())  # Handle missing values\n",
    "\n",
    "\n",
    "def apply_feature_weights(X, role_type):\n",
    "    weights = {\n",
    "        \"Anchor\":        {\"runs\": 1.5, \"avg\": 1.3, \"sr\": 1.2, \"fours\": 1.0, \"sixes\": 1.0, \"boundary_pct\": 0.6},\n",
    "        \"Balanced\":      {\"runs\": 1.0, \"avg\": 1.0, \"sr\": 1.0, \"fours\": 0.8, \"sixes\": 0.8, \"boundary_pct\": 1.0},\n",
    "        \"Power Hitter\":  {\"runs\": 0.2, \"avg\": 0.4, \"sr\": 1.8, \"fours\": 2.0, \"sixes\": 2.0, \"boundary_pct\": 2.5},\n",
    "        \"Finisher\":      {\"runs\": 0.4, \"avg\": 0.3, \"sr\": 1.6, \"fours\": 2.1, \"sixes\": 2.2, \"boundary_pct\": 2.0}\n",
    "    }\n",
    "    \n",
    "    weighted_X = X.copy()\n",
    "    for feature, weight in weights[role_type].items():\n",
    "        if feature in weighted_X.columns:\n",
    "            weighted_X[feature] *= weight\n",
    "    \n",
    "    return weighted_X\n",
    "\n",
    "\n",
    "# Inexperienced Players (Less than 20 matches or 500 runs)\n",
    "inexperienced_players = df[(df[\"mat\"] < 20) | (df[\"runs\"] < 500)].copy()\n",
    "experienced_players = df[(df[\"mat\"] >= 20) & (df[\"runs\"] >= 500)].copy()\n",
    "\n",
    "# K-Means for Inexperienced Players\n",
    "X_inexperienced = apply_feature_weights(X.loc[inexperienced_players.index], \"Balanced\")\n",
    "kmeans_inexperienced = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "inexperienced_players.loc[:, \"role\"] = kmeans_inexperienced.fit_predict(X_inexperienced)\n",
    "\n",
    "inexperienced_players[\"role\"] = inexperienced_players[\"role\"].map({\n",
    "    0: \"Inexperienced - Potential Anchor\",\n",
    "    1: \"Inexperienced - Potential Hitter\"\n",
    "})\n",
    "\n",
    "# Power Hitter Identification (Rule-Based)\n",
    "X_experienced_power = apply_feature_weights(X.loc[experienced_players.index], \"Power Hitter\")\n",
    "power_hitter_criteria = (\n",
    "    (experienced_players[\"boundary_pct\"] > 60) &\n",
    "    (experienced_players[\"sr\"] > 135)\n",
    ")\n",
    "experienced_players.loc[power_hitter_criteria, \"role\"] = \"Power Hitter\"\n",
    "\n",
    "# Finisher Identification (Rule-Based)\n",
    "finisher_criteria = (\n",
    "    (experienced_players[\"sr\"] > 160) &\n",
    "    ((experienced_players[\"fours\"] + experienced_players[\"sixes\"]) > 40)\n",
    ")\n",
    "experienced_players.loc[finisher_criteria, \"role\"] = \"Finisher\"\n",
    "\n",
    "# GMM for Remaining Experienced Players\n",
    "non_power_hitters = experienced_players[experienced_players[\"role\"].isna()]\n",
    "X_experienced_gmm = apply_feature_weights(X.loc[non_power_hitters.index], \"Balanced\")\n",
    "\n",
    "gmm = GaussianMixture(n_components=4, covariance_type='diag', random_state=42)\n",
    "non_power_hitters.loc[:, \"GMM_Cluster\"] = gmm.fit_predict(X_experienced_gmm)\n",
    "\n",
    "# GMM Role Mapping \n",
    "role_mapping = {\n",
    "    0: \"Anchor\",\n",
    "    1: \"Balanced Player\",\n",
    "    2: \"Power Hitter\",\n",
    "    3: \"Finisher\"\n",
    "}\n",
    "non_power_hitters.loc[:, \"role\"] = non_power_hitters[\"GMM_Cluster\"].map(role_mapping)\n",
    "\n",
    "# Combine Experienced Data Back\n",
    "experienced_players.update(non_power_hitters)\n",
    "\n",
    "# Final Combined Dataset\n",
    "df_final = pd.concat([experienced_players, inexperienced_players])\n",
    "\n",
    "\n",
    "X_final = df_final[features]\n",
    "y_final = df_final[\"role\"]\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y_final, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Neural Network with Hyperparameter Tuning\n",
    "nn_params = {\n",
    "    'hidden_layer_sizes': [(256, 128, 64), (512, 256, 128)],\n",
    "    'activation': ['relu'],\n",
    "    'alpha': [0.0005, 0.001],\n",
    "    'learning_rate_init': [0.005],\n",
    "    'max_iter': [1500, 2000]\n",
    "}\n",
    "nn_model = GridSearchCV(MLPClassifier(random_state=42), nn_params, cv=3)\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_nn = nn_model.best_estimator_.predict(X_test)\n",
    "y_pred_proba = nn_model.best_estimator_.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print(\"Neural Network Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "print(f\"Log Loss: {log_loss(y_test, y_pred_proba):.4f}\")\n",
    "\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=3)),\n",
    "    ('mlp_classifier', nn_model.best_estimator_)\n",
    "])\n",
    "\n",
    "# Saving the Unified Pipeline\n",
    "joblib.dump(full_pipeline, \"batting_data_model.pkl\")\n",
    "\n",
    "print(\"Batting data model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173904e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline fitting\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import joblib\n",
    "\n",
    "# Ensure the pipeline is fitted before saving\n",
    "full_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=3)),\n",
    "    ('mlp_classifier', MLPClassifier(random_state=42, max_iter=1500))\n",
    "])\n",
    "\n",
    "full_pipeline.fit(X_train, y_train)  # FITTING STEP\n",
    "joblib.dump(full_pipeline, \"batting_data_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the saved model\n",
    "model = joblib.load(\"batting_data_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Testing\n",
    "test_data = pd.DataFrame({\n",
    "    \"mat\": [100, 90, 85, 8, 150],   \n",
    "    \"runs\": [450, 3800, 5000, 200, 3000],  \n",
    "    \"avg\": [18, 40, 20, 45, 25],   \n",
    "    \"sr\": [130, 110, 110, 120, 180],  \n",
    "    \"career_length\": [8, 9, 10, 2, 12],  \n",
    "    \"fours\": [15, 230, 300, 25, 300],  \n",
    "    \"sixes\": [8, 105, 70, 10, 200]   \n",
    "})\n",
    "\n",
    "test_data[\"boundary_pct\"] = (\n",
    "    (test_data[\"fours\"] * 4 + test_data[\"sixes\"] * 6) / test_data[\"runs\"]\n",
    ").fillna(0)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18bcca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_roles = model.predict(test_data)\n",
    "print(\"Predicted Roles:\", predicted_roles)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
